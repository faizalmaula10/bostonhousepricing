# -*- coding: utf-8 -*-
"""Linear Regression ML Implementation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z0MPjmq_SYcqMbKJkr1P4Fi6knter48I
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import sklearn

data=pd.read_csv('/content/BostonHousing.csv')

data

data.columns

"""## Lets load the Boston House Pricing Dataset

## Preparing The Dataset
"""

dataset=pd.DataFrame(data,columns=data.columns)

dataset.head()

dataset.head()

dataset.info()

## Summarizing The Stats of the data
dataset.describe()

## Check the missing Values
dataset.isnull().sum()

### EXploratory Data Analysis
## Correlation
dataset.corr()

import seaborn as sns
sns.pairplot(dataset)

"""## Analyzing The Correlated Features"""

dataset.corr()

plt.scatter(dataset['crim'],dataset['medv'])
plt.xlabel("Crime Rate")
plt.ylabel("Price")

plt.scatter(dataset['rm'],dataset['medv'])
plt.xlabel("RM")
plt.ylabel("Price")

import seaborn as sns
sns.regplot(x="rm",y="medv",data=data)

sns.regplot(x="lstat",y="medv",data=data)

sns.regplot(x="ptratio",y="medv",data=data)

dataset

## Independent and Dependent features

X=data.iloc[:,:-1]
y=data.iloc[:,-1]

X.head()

y

##Train Test Split
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)

X_train

X_test

## Standardize the dataset
from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()

X_train=scaler.fit_transform(X_train)

X_test=scaler.transform(X_test)

import pickle
pickle.dump(scaler,open('scaling.pkl','wb'))

X_train

X_test

"""## Model Training"""

from sklearn.linear_model import LinearRegression

regression=LinearRegression()

regression.fit(X_train,y_train)

## print the coefficients and the intercept
print(regression.coef_)

print(regression.intercept_)

## on which parameters the model has been trained
regression.get_params()

### Prediction With Test Data
reg_pred=regression.predict(X_test)

reg_pred

"""## Assumptions"""

## plot a scatter plot for the prediction
plt.scatter(y_test,reg_pred)

## Residuals
residuals=y_test-reg_pred

residuals

## Plot this residuals

sns.displot(residuals,kind="kde")

## Scatter plot with respect to prediction and residuals
## uniform distribution
plt.scatter(reg_pred,residuals)

from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error

print(mean_absolute_error(y_test,reg_pred))
print(mean_squared_error(y_test,reg_pred))
print(np.sqrt(mean_squared_error(y_test,reg_pred)))

"""## R square and adjusted R square

Formula

**R^2 = 1 - SSR/SST**


R^2	=	coefficient of determination
SSR	=	sum of squares of residuals
SST	=	total sum of squares
"""

from sklearn.metrics import r2_score
score=r2_score(y_test,reg_pred)
print(score)



"""**Adjusted R2 = 1 â€“ [(1-R2)*(n-1)/(n-k-1)]**

where:

R2: The R2 of the model
n: The number of observations
k: The number of predictor variables
"""

#display adjusted R-squared
1 - (1-score)*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)

"""## New Data Prediction"""

pred=X.iloc[0].values.reshape(1, -1)

##transformation of new data
scaler.transform(pred)

regression.predict(scaler.transform(pred))

"""## Pickling The Model file For Deployment"""

import pickle

pickle.dump(regression,open('regmodel.pkl','wb'))

pickled_model=pickle.load(open('regmodel.pkl','rb'))

## Prediction
pickled_model.predict(scaler.transform(pred))

